{"version":3,"file":"IAggregatedStore.js","sourceRoot":"","sources":["IAggregatedStore.ts"],"names":[],"mappings":"","sourcesContent":["// eslint-disable-next-line import/no-nodejs-modules\nimport type { EventEmitter } from 'events';\nimport type * as RDF from '@rdfjs/types';\nimport type { AsyncIterator } from 'asynciterator';\n\n/**\n * A StreamingStore allows data lookup and insertion to happen in parallel.\n * Concretely, this means that `match()` calls happening before `import()` calls, will still consider those triples that\n * are inserted later, which is done by keeping the response streams of `match()` open.\n * Only when the `end()` method is invoked, all response streams will close, and the StreamingStore will be considered\n * immutable.\n *\n * WARNING: `end()` MUST be called at some point, otherwise all `match` streams will remain unended.\n */\nexport interface IAggregatedStore<Q extends RDF.BaseQuad = RDF.Quad, S extends RDF.Store<Q> = RDF.Store<Q>>\n  extends RDF.Source<Q>, RDF.Sink<RDF.Stream<Q>, EventEmitter> {\n  /**\n   * If this aggregated has started processing.\n   */\n  started: boolean;\n\n  /**\n   * If iterators created during the `match` call are still running.\n   */\n  hasRunningIterators: () => boolean;\n\n  /**\n   * Mark this store as ended.\n   *\n   * This will make sure that all running and future `match` calls will end,\n   * and all next `import` calls to this store will throw an error.\n   */\n  end: () => void;\n\n  match: (\n    subject?: RDF.Term | null,\n    predicate?: RDF.Term | null,\n    object?: RDF.Term | null,\n    graph?: RDF.Term | null,\n  ) => AsyncIterator<Q>;\n}\n"]}